---
title: "Layer-Wise Relevance Propagation with Conservation Property for ResNet"
collection: publications
permalink: /publication/lrp-for-resnet
excerpt: "XAI, LRP, ResNet"
date: 2024-09-29
venue: "ECCV24"
paperurl: "https://arxiv.org/pdf/2407.09115"
citation: "Otsuki, Seitaro, Tsumugi Iida, <b>Félix Doublet</b>, Tsubasa Hirakawa, Takayoshi Yamashita, Hironobu Fujiyoshi, and Komei Sugiura. &quot;Layer-Wise Relevance Propagation with Conservation Property for ResNet.&quot; In <i>European Conference on Computer Vision</i>, pp. 349-364. Springer, Cham, 2025."
---

The black-box nature of neural network models sometimes masks the underlying logic of their inference processes. This opacity presents significant challenges in verifying the validity of the models’ predictions. Layer-wise Relevance Propagation (LRP) stands out as a well-established method that transparently traces the flow of a model's prediction backward through its architecture by backpropagating relevance scores. However, LRP has not fully considered the existence of a skip connection, and its application to the widely used ResNet architecture has not been thoroughly explored.

<p><img src="https://github.com/FelixDou/FelixDou.github.io/raw/86ba8bf5d0caf18d363e96d113f0b5fd5283bc2f/images/eye-catch.png" alt="Method" style="max-width: 100%; height: auto;"></p>

**Project page:** [Click here](https://5ei74r0.github.io/lrp-for-resnet.page/)

**Paper link:** [Click here](https://arxiv.org/pdf/2407.09115)
